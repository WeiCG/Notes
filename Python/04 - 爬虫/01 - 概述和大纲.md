# 爬虫开始和总结

> 本笔记写于2020年1月30日。Python版本为3.7.4，编辑器是VS code
>
> 总参考文献：
>
> 1. [崔庆才著《Python 3网络爬虫开发实战》](https://item.jd.com/12333540.html)
> 2. B站视频[av44518113](https://www.bilibili.com/video/av44518113)
> 3. Python官网文档
> 5. [Requests库官方文档](https://requests.readthedocs.io/en/master/)
> 5. [W3School中文网站的XPath教程](https://www.w3school.com.cn/xpath/index.asp)
> 6. [lxml库官方文档](https://lxml.de/)
>
> PS：如果笔记中有任何错误，欢迎在评论中指出，我会及时回复并修改，谢谢

## 爬虫概述

学习爬虫的第一步就是要明白，到底什么爬虫？明白了本质才能真正的学会爬虫。

在了解爬虫的本质前，首先需要有三个”看作“：

- 将整个互联网看作一张大网
- 将互联网上的一个个网站看作网的节点
- 将网站之间的链接看作网的连线

有了这三个”看作“，就可以对爬虫有一个清楚的认识。

爬虫就是一只爬行在这张网上的蜘蛛。每当蜘蛛到达一个节点处，意味着该网页已经被”爬取“到，然后，蜘蛛还可以沿着连线爬向下一个节点继续爬取网站，直到这张网上的所有节点全部被爬行到或者完成了爬取任务。

## 爬虫的基本步骤

### 获取页面

爬虫首先要做的就是获取网页，而获取页面的过程就像是蜘蛛沿着连线向节点爬行的过程。其实就是爬虫程序向网站的服务器发送了一个请求，然后服务器接收请求并返回响应，而返回的响应体便是网页的源代码。

因此，最关键的的步骤就是：

1. 如何构建一个请求并发送给服务器
2. 如何接收响应并从中解析出网页源代码

而实际上，Python中有大量的第三方库都已经实现了这个复杂的过程，只需要使用第三方库即可

### 提取内容

解析出网页源代码后，接下来就需要分析页面从中提取出我们想要的数据。这是非常重要的一步，毕竟如果只是单纯的获取到网页源代码，作用并不大，只有将有效数据提取并整理后，才以便后续的分析。

提取数据有两种方法

1. 构建正则表达式提取，这种方法非常强大而且万能，但构建过程非常复杂而且容易出错，但如果使用第二种方法提取不出来时，可以尝试使用
2. 使用Python第三方库。由于网页结构是有一定规律的，我们可以根据这些规律来提取出相应的信息

将数据提取出来后，将数据存储到数据库或远程服务器中，以便后续使用

## 爬虫的学习过程

## 爬虫总结

爬虫看似简单，但实现却非常困难，这主要是因为

1. 现在的网站大多都采用了反爬虫技术
2. 互联网上的网页何止千万，如此庞大的数量如何实现正确的爬取
3. 爬虫成功后如何实现数据的有效提取

